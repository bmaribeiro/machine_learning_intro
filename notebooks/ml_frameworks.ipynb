{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Frameworks for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn how to operate with two of the most fundamental frameworks when it comes to Machine Learning: Pandas and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy (https://github.com/numpy/numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is a Python library aimed at array operations. This library is well-suited for Machine Learning tasks, where speed and resources are very important (processing using NumPy arrays is up to 50x faster than doing so using Python lists)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by installing and importing the library. (You just have to run the next cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Usually, you need to create a Python environment and install all the required packages there. However, since this is a jupyter notebook tutorial, we can do it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do some exercises leveraging the potentialities of NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 - Create a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite simple to create a numpy array. You'll see an example and reproduce the method, using a different sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_array = np.array([1, 2, 3, 4, 5])\n",
    "print(\"Here's an example: \" + str(example_array) + \"\\n\")\n",
    "print(\"Now it's your turn.\\n\")\n",
    "\n",
    "your_array = #insert code here\n",
    "\n",
    "print(your_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we used a list to create a NumPy array, but we can also use tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_from_tuple = np.array((1, 2, 3, 4, 5))\n",
    "\n",
    "print(array_from_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 - Multi-dimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've introduced one-dimensional arrays (which are basically matrices), but NumPy offers the possibility to create arrays with n dimensions. See an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_3d = np.array([[2, 3, 4], [5, 6, 7], [2, 3, 7]])\n",
    "\n",
    "print(array_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create an array with 7 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_7d = #insert code here\n",
    "\n",
    "print(array_7d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the shape of your array using the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array_7d.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4 - Indexation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPy, you access an element within an array using straight brackets - [] - same as you do with Python lists. See the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "print(array[0])\n",
    "print(array[1])\n",
    "print(array[7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the code necessary to access and print the 9th element of the previous array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninth = #insert code here\n",
    "\n",
    "print(ninth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the length of the array? Inser the code needed to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_len = #insert code here\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the length of the array is 9, the 9th element of the array is the last one. You can access the last element of an array in a different manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_element = array[-1]\n",
    "\n",
    "print(last_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-dimensional arrays, you need to use multiple indexes. Consider the following bi-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidim_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(bidim_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to access the element with value \"4\" in this array, which is situate in the second row, first column. How can you do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_element = #insert code here\n",
    "\n",
    "print(required_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5 - Array Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know all about indexing, let's talk slicing. You can slice sub-parts of arrays using the following notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "sliced_array = array[1:6]\n",
    "\n",
    "print(sliced_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn. Access and print the 3 middle elements of the array (\"4\", \"5\", and \"6\") using a slicing technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = #insert code here\n",
    "\n",
    "print(slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use negative indexes. See the example and try it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array[-6:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "your_slice = #insert code here\n",
    "\n",
    "print(yout_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a sequence of elements through steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_slice = array[1:9:2]\n",
    "\n",
    "print(step_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your move. Try different step and limit combinations (including negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_step_slice = #insert code here\n",
    "\n",
    "print(my_step_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6 - Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've only worked with integers so far, but ndarrays are compatible with other types of data. Try to create an array out of a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_array = #insert code here\n",
    "\n",
    "print(str_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work? Now try a list of floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_array = #insert code here\n",
    "\n",
    "print(flt_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert arrays to a different data type (as long as the conversion is possible). Check the following conversion of an integer array to a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_array = np.array([0, 1, 0, 0])\n",
    "\n",
    "bool_array = int_array.astype('bool')\n",
    "\n",
    "print(bool_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert the float array you created into an integer array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_int_array = #insert code here\n",
    "\n",
    "print(my_int_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7 - Join and Split Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to join the contents of two or more arrays in a single array, we can use the concatenate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])\n",
    "\n",
    "arr = np.concatenate((arr1, arr2))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the contents of the following 4 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([5, 23, 4, 99])\n",
    "arr2 = np.array([98, 3, 15])\n",
    "arr3 = np.array([70, 20, 12])\n",
    "arr4 = np.array([1])\n",
    "\n",
    "final_arr = # insert code here\n",
    "print(final_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the array you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results = np.array_split(final_arr, 2)\n",
    "\n",
    "print(split_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn. Split final_arr into 5 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_arr = # insert code here\n",
    "\n",
    "print(splitted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8 - Search Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data analysis tasks, it may be useful to search for the instances that verify a certain condition within an array. For this purpose, NumPy offers the method where, which does exacly that. See the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([4, 93, 83, 94, 12])\n",
    "\n",
    "print(np.where(arr==12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the algorithm correctly situated the value \"12\" in the fourth position of the array.\n",
    "You can use any type of condition for your search. For certain tasks, it might be useful to situate all instances verifying a certain condition. For instance, considering an array containing the ages of all the patients within a clinical facility, we might want to identify the adults exclusively (+ 18 yo). How would you do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.array([8, 19, 18, 29, 88, 82, 3, 45, 51, 54, 74, 54, 66, 23, 3, 7, 92, 65, 64])\n",
    "\n",
    "adults_idx = #insert code here\n",
    "\n",
    "print(adults_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now keep in mind the previous example. What if you wanted to sort the patients according to their age? NumPy also has a method for that: np.sort. How do you think you can implement it? Complete the following cell adequately to obtain an ordered ages array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_ages = #insert code here\n",
    "\n",
    "print(ordered_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we do not want an ordered representation, but the ordered indexes instead, so that we can access them in the original array. For that, we use np.argsort. Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indexes = np.argsort(ages)\n",
    "\n",
    "print(sorted_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think happens when you apply np.sort to a string array? Check your guess in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_arr = [\"what\", \"is\", \"going\", \"on\", \"here\"]\n",
    "\n",
    "sorted_str_arr = #insert code here\n",
    "\n",
    "print(sorted_str_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9 - Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is also a powerful tool to filter information. Check the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# We want only the odd numbers in the array\n",
    "odd_numbers = []\n",
    "for number in arr:\n",
    "    if number % 2 != 0:\n",
    "        odd_numbers.append(True)\n",
    "    else:\n",
    "        odd_numbers.append(False)\n",
    "\n",
    "filtered_array = arr[odd_numbers]\n",
    "\n",
    "print(filtered_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the indexes of the elements to filter arrays. Consider Exercise 8, where you had to search for the adult patients within an array of patients' ages. How can you obtain an array composed exclusively by ages of adult patients using filtering techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adults_idxs = #insert code here\n",
    "\n",
    "filtered_ages = #insert code here\n",
    "\n",
    "print(filtered_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You concluded your introductory class on NumPy! Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas (https://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is the most famous Python library for data analysis. In this tutorial, you'll learn all the skills needed to operate with pandas in the context of Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by installing and importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by understanding the two major data representations in pandas: DataFrames and Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pandas series is nothing more than a sequence of values, much like a Python list or a NumPy array. Check next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_series = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "print(sample_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Series is basically a DataFrame column. But let's talk about those by the way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is a table containing an array (matrix) of individual entries. Each entry has a row and a column associated. Let's see an example with made-up clinical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clincial_df = pd.DataFrame({'Age': np.array([18, 61, 34]), 'Diseases': ['None', 'Diabetes', 'Hypertension'], 'Smoking History': ['Non-smoker', 'Past smoker', 'Current smoker']})\n",
    "\n",
    "print(clinical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we can represent and organize different types of data with DataFrames. Create a random DataFrame with movie-related data (be creative!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = #insert your code here\n",
    "\n",
    "print(movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 - Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I'm sure you'll agree it's pretty easy to create simple DataFrames manually, data scientists do not usually work with small data quatities such as the one you just created. Instead, they need to import data from big and heavy data files. Pandas is compatible with the most popular data formats such as \".csv\", \".txt\", \".json\", \".sql\", among others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing tabular data from a \".csv\" file. The data refers to the top songs listened in Spotify from 2009 to 2019 (https://www.kaggle.com/datasets/paradisejoy/top-hits-spotify-from-20002019?select=songs_normalize.csv). To load it, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data = pd.read_csv(\"songs_normalize.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully loaded the dataset from a \".csv\" file. Check it's size with the attribute \"shape\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame shape:\")\n",
    "print(songs_data.shape)\n",
    "\n",
    "print(\"This DataFrame has \" + str(songs_data.shape[0]) + \" rows and \" + str(songs_data.shape[1]) + \" columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the contents of the DataFrame by analyzing its first few rows. You do that using the atribute \"head\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(songs_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2 - Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with data, you need to know how to access data. Pandas offers you a fluid way to do that through DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access a column in many ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method 1:\")\n",
    "songs_data.song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method2\")\n",
    "\n",
    "songs_data['song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method3\")\n",
    "\n",
    "songs_data.loc[:,'song']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although they all work, you should take special interest in the third method, as it is more flexible than the other ones in terms of data accessibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the \"popularity\" column using the third method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_col = #insert code here\n",
    "\n",
    "print(popularity_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".loc is a label-based selection method. It has a similar, correspondent index-based selection method: .iloc. Try it! Select and print the second column (songs columns) of the songs DataFrame using .iloc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_col = #insert code here\n",
    "\n",
    "print(second_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This methods allow you to select both rows and columns at the same time, and you can even select groups of both entities (similar to what you did when slicing NumPy arrays). Check this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = songs_data.iloc[1:3, 0:4]\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument refers to the rows, while the second indicates the columns. Now it's your turn, select the contents of the last three columns, for the patients from 6 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = #insert your code here\n",
    "print(selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .loc method also allows you to perform conditional selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.loc[songs_data.artist == 'Britney Spears']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself. Select all data correspondent to songs with energy above 0.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = #insert code here\n",
    "\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 - Data Analysis and Summarization with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun really begins! As you may know, a fundamental part of the machine learning workflow is the analysis of the data you'll be working with. You need to know your data, in order to understand how you can make the most out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas describe method provides an overview on the fundamental statistical values describing the distribution of each variable (column) within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: As you can see, not all variables are represented in this description, such as the \"artist\" column. This happens because those variables are cathegorical, and are therefore uncompatible with statistical distributions. You'll learn how to deal with those later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also study a single variable individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.year.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we challenge you to try the following methods, which are appliable in a similar way to the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.1. To see a list of unique values, we can use the unique() method. Check all the different artists represented in the dataset, applying this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_artists = #insert code here\n",
    "\n",
    "unique_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.2. Sometimes, it might be useful to check how many times each value appears in a column. Check how many times is each artis represented. (To do this, you'll need the value_counts() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_representivity = #insert code here\n",
    "\n",
    "artists_representivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This method is especially useful to search for data imbalance, which happens when the distribution of a certain variable is biased towards a certain value. In machine learning tasks, it is fundamental to test this trait in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4 - Indexing and Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexation is also a relevant topic. songs_data is ordered, but that might not always be the case. To guarantee your dataset is ordered, you can use the reset_index() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the method preserves the initial indexes as a new column, to get rid of this useless column, you should set \"drop\" as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, it might be useful to order the data according to a certain variable. Check the next example, where we ordered songs according to their associated energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.sort_values(by='energy', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to order the entries in songs_data descending according to the \"popularity\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_ordered_data = #insert code here\n",
    "\n",
    "popularity_ordered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sort by index, using the following method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you can sort more than one column at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_data.sort_values(by=['popularity', 'energy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method uses the second criterion when the first one is not enough to distinguish entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5 - Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entries missing values are given the value NaN, short for \"Not a Number\". For technical reasons these NaN values are always of the float64 dtype. Knowing how to deal with missing values is an essential skill for any data scientist. Fortunately, pandas offers some methods to help us do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we've been working upon has no missing input occurrences. However, in real data, that happens only in very rare occasions. Run the following cell to obtain a more realistic dataset, by fabricating missing inputs. (This is not something you'll do often, in fact, if you have complete datasets, that's all the better for you! So don't waste your time here, go ahead!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_missing_data = songs_data.copy()\n",
    "\n",
    "songs_missing_data['popularity'][songs_missing_data.loc[:, 'popularity'] > 70] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by selecting NaN entries in the DataFrame. The method pd.isnull() returns a boolean data representation refflecting wether or not each element corresponds to a missing input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(songs_missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this to a single column, we can then use this result to select exclusively the entries of the DataFrame with attributed values regarding the variable chosen. Perform this selection process according to the \"popularity\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_info = #insert code here\n",
    "\n",
    "selected_songs = songs_data[select_info]\n",
    "\n",
    "selected_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you lost a lot of entries. You need to get rid of all missing values in order to train machine learning models. For this reason, this exclusion process is not very viable, considering you'll lose a lot of information in the process. Instead, data scientists usually apply missing imputation methods. A simple imputation method offered by pandas relies on the substitution of all the missing instances for a specific value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_missing_data.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all values were replaced by the element \"Unknown\". However, this is not very helpful for that variable specifically... There are other, better options of values to perform this substitution, such as statistical values related to that variable's distribution within the dataset. Apply the method presented, replacing the missing inputs with the mean value of the known entries, for the popularity variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = songs_missing_data.popularity.mean()\n",
    "\n",
    "imputed_data = #insert code here\n",
    "\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same, but using the median instead. (Tip there's a method to calculate median similar to the one used above to calculate the mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_value = #insert code here\n",
    "\n",
    "imputed_data = #insert code here\n",
    "\n",
    "imputed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAREFUL! In this case, we were able to apply the \"fillna\" method because only one variable had missing inputs. However, it is common for that to happen in more than one column. In that situtation, we could not apply this method using a single value for all variables, since they should present very distinct distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this is still not ideal in some cases. In this dataset, we forged the missing values, and they were all correspondent to values outside the known data distribution, which is now limited to the value of 70. For this reason, these estimation methods are far from the true values that are missing. There are other, more robust ways to deal with missing inputs, however, we will not cover them in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5 - Combining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you might have more than one data source. Since you want to get as much useful data as possible to train your models, you need to consider all these data. Run the following cell, which will load a different dataset from the one we've been working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_locations = pd.read_csv(\"subway_locations_in_us.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check it's content (use the head() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_head = #insert code here\n",
    "\n",
    "df_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = #insert code here\n",
    "\n",
    "df_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend that both these datasets are related to the songs (as if each song was played in a specific subway location). However, we have only 2000 songs and 22645 subway locations represented. Let's pretend that only the 2000 first columns from the subway_locations DataFrame are related to our problem. Run the following cell. (This is purely hypothetical, just for the sake of this exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_locations = subway_locations.loc[0:1999, :]\n",
    "\n",
    "subway_locations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have compatible data. But it's still separated. We can solve that using the join method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = songs_data.join(subway_locations)\n",
    "\n",
    "complete_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have variables from both datasets. We have, however, an unwanted column \"Unnamed:0\", which stores the indexes of the second DataFrame. We can get rid of it through the \"drop\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.drop(\"Unnamed: 0\", axis='columns')\n",
    "\n",
    "complete_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilá! A new DataFrame composed by the content of both data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find yourself in a situation where you want to concatenate information vertically, instead of horizontaly, i.e., you might want to add new entries (rows) to your dataset. To do that, you should use the method pd.concat, which receives a list of DataFrames as input and returns a merged version of them as a single DataFrame. Let's concatenate songs_data with a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_songs = pd.concat([songs_data, songs_data.copy()])\n",
    "\n",
    "double_songs.shape\n",
    "\n",
    "double_songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it has doubled the number of entries, as we expected. Since the columns from both DataFrames are the same, there are no conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a lot more methods to offer. You can explore its content here: https://pandas.pydata.org/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
